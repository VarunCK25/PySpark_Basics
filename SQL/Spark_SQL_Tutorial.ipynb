{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register temp table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTags = (spark\n",
    "            .read\n",
    "            .options(header=True, inferSchema=True)\n",
    "            .csv(\"..\\\\Resources\\\\question_tags_10K.csv\")\n",
    "            .toDF(\"id\", \"tag\")\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTags.createOrReplaceTempView(\"so_tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all tables in Spark's catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='so_tags', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all tables in Spark's catalog using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        |  so_tags|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTags.select(\"id\", \"tag\").limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+\n",
      "| id|            tag|\n",
      "+---+---------------+\n",
      "|  1|           data|\n",
      "|  4|             c#|\n",
      "|  4|       winforms|\n",
      "|  4|type-conversion|\n",
      "|  4|        decimal|\n",
      "+---+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id, tag from so_tags limit 10\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTags.filter(\"tag == 'php'\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|tag|\n",
      "+---+---+\n",
      "| 23|php|\n",
      "| 42|php|\n",
      "| 85|php|\n",
      "|126|php|\n",
      "|146|php|\n",
      "+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from so_tags where tag = 'php'\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of php tags = {}\".format(dfTags.filter(\"tag == 'php'\").count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|php_count|\n",
      "+---------+\n",
      "|      133|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select count(*) as php_count from so_tags where tag='php'\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTags.filter(\"tag like 's%'\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|          tag|\n",
      "+---+-------------+\n",
      "| 25|      sockets|\n",
      "| 36|          sql|\n",
      "| 36|   sql-server|\n",
      "| 40| structuremap|\n",
      "| 48|submit-button|\n",
      "+---+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from so_tags where tag like 's%'\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL where with and clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTags.filter(\"tag like 's%'\").filter(\"id == 25 or id == 108\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|    tag|\n",
      "+---+-------+\n",
      "| 25|sockets|\n",
      "|108|    svn|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from so_tags where tag like 's%' and (id = 25 or id = 108)\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL IN clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTags.filter(\"id in (25, 108)\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|      tag|\n",
      "+---+---------+\n",
      "| 25|      c++|\n",
      "| 25|        c|\n",
      "| 25|  sockets|\n",
      "| 25|mainframe|\n",
      "| 25|      zos|\n",
      "+---+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from so_tags where id in (25, 108)\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTags.groupBy(\"tag\").count().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|        tag|count|\n",
      "+-----------+-----+\n",
      "|type-safety|    4|\n",
      "|    jbutton|    1|\n",
      "|     iframe|    2|\n",
      "|  svn-hooks|    2|\n",
      "|  standards|    7|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select tag, count(*) as count from so_tags group by tag\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Group By with having clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTags.groupBy(\"tag\").count().filter(\"count > 5\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|          tag|count|\n",
      "+-------------+-----+\n",
      "|    standards|    7|\n",
      "|     keyboard|    8|\n",
      "|          rss|   12|\n",
      "|documentation|   15|\n",
      "|      session|    6|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select tag, count(*) as count from so_tags group by tag having count > 5\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Order by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTags.groupBy(\"tag\").count().filter(\"count > 5\").orderBy(\"tag\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|           tag|count|\n",
      "+--------------+-----+\n",
      "|          .net|  351|\n",
      "|      .net-2.0|   14|\n",
      "|      .net-3.5|   30|\n",
      "|         64bit|    7|\n",
      "|actionscript-3|   22|\n",
      "+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select tag, count(*) as count from so_tags group by tag having count > 5 order by tag\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typed dataframe, filter and temp table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuestionsCSV = (spark\n",
    "                    .read\n",
    "                    .options(header=True, inferSchema=True, dateFormat=\"yyyy-MM-dd HH:mm:ss\")\n",
    "                    .csv(\"..\\\\Resources\\\\questions_10K.csv\")\n",
    "                    .toDF(\"id\", \"creation_date\", \"closed_date\", \"deletion_date\", \"score\", \"owner_userid\", \"answer_count\")\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cast columns to data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuestions = dfQuestionsCSV.select(\n",
    "                                col(\"id\").cast(\"integer\"),\n",
    "                                col(\"creation_date\").cast(\"timestamp\"),\n",
    "                                col(\"closed_date\").cast(\"timestamp\"),\n",
    "                                col(\"deletion_date\").cast(\"date\"),\n",
    "                                col(\"score\").cast(\"integer\"),\n",
    "                                col(\"owner_userid\").cast(\"integer\"),\n",
    "                                col(\"answer_count\").cast(\"integer\")\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuestionsSubset = dfQuestions.filter(\"score > 400 and score < 410\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### register temp table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuestionsSubset.createOrReplaceTempView(\"so_questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfQuestionsSubset.join(dfTags, \"id\", \"inner\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "| id|      tag| id|      creation_date|        closed_date|deletion_date|score|owner_userid|answer_count|\n",
      "+---+---------+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "|888|   xdebug|888|2008-08-04 04:48:21|2016-08-04 14:52:00|         null|  405|         131|          30|\n",
      "|888| phpstorm|888|2008-08-04 04:48:21|2016-08-04 14:52:00|         null|  405|         131|          30|\n",
      "|888|debugging|888|2008-08-04 04:48:21|2016-08-04 14:52:00|         null|  405|         131|          30|\n",
      "|888|  eclipse|888|2008-08-04 04:48:21|2016-08-04 14:52:00|         null|  405|         131|          30|\n",
      "|888|      php|888|2008-08-04 04:48:21|2016-08-04 14:52:00|         null|  405|         131|          30|\n",
      "+---+---------+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select t.*, q.* from so_questions q inner join so_tags t on t.id = q.id\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Left Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfQuestionsSubset.join(dfTags, \"id\", \"left_outer\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "| id|      tag| id|      creation_date|        closed_date|deletion_date|score|owner_userid|answer_count|\n",
      "+---+---------+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "|888|   xdebug|888|2008-08-04 04:48:21|2016-08-04 14:52:00|         null|  405|         131|          30|\n",
      "|888| phpstorm|888|2008-08-04 04:48:21|2016-08-04 14:52:00|         null|  405|         131|          30|\n",
      "|888|debugging|888|2008-08-04 04:48:21|2016-08-04 14:52:00|         null|  405|         131|          30|\n",
      "|888|  eclipse|888|2008-08-04 04:48:21|2016-08-04 14:52:00|         null|  405|         131|          30|\n",
      "|888|      php|888|2008-08-04 04:48:21|2016-08-04 14:52:00|         null|  405|         131|          30|\n",
      "+---+---------+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select t.*, q.* from so_questions q left outer join so_tags t on t.id = q.id\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Right Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTags.join(dfQuestionsSubset, \"id\", \"right_outer\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+----+-------------+-----------+-------------+-----+------------+------------+\n",
      "| id|            tag|  id|creation_date|closed_date|deletion_date|score|owner_userid|answer_count|\n",
      "+---+---------------+----+-------------+-----------+-------------+-----+------------+------------+\n",
      "|  1|           data|null|         null|       null|         null| null|        null|        null|\n",
      "|  4|             c#|null|         null|       null|         null| null|        null|        null|\n",
      "|  4|       winforms|null|         null|       null|         null| null|        null|        null|\n",
      "|  4|type-conversion|null|         null|       null|         null| null|        null|        null|\n",
      "|  4|        decimal|null|         null|       null|         null| null|        null|        null|\n",
      "+---+---------------+----+-------------+-----------+-------------+-----+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select t.*, q.* from so_questions q right outer join so_tags t on t.id = q.id\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register User Defined Function (UDF) Function to prefix a String with so_ short for StackOverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefixStackoverflow(s):\n",
    "    return \"so_\" + s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register User Defined Function (UDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.prefixStackoverflow(s)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"prefix_so\", prefixStackoverflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use udf prefixso to augment each tag value with so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|    prefix_so(tag)|\n",
      "+---+------------------+\n",
      "|  1|           so_data|\n",
      "|  4|             so_c#|\n",
      "|  4|       so_winforms|\n",
      "|  4|so_type-conversion|\n",
      "|  4|        so_decimal|\n",
      "+---+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select id, prefix_so(tag) from so_tags\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|        tag|\n",
      "+-----------+\n",
      "|type-safety|\n",
      "|    jbutton|\n",
      "|     iframe|\n",
      "|  svn-hooks|\n",
      "|  standards|\n",
      "+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select distinct tag from so_tags\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
