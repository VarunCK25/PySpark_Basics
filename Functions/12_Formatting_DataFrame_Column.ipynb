{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating List of Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "donuts = [(\"plain donut\", 1.50, \"2018-04-17\"), (\"vanilla donut\", 2.0, \"2018-04-01\"), (\"glazed donut\", 2.50, \"2018-04-02\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe from Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(donuts).toDF(\"Donut Name\", \"Price\", \"Purchase Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-------------+\n",
      "|   Donut Name|Price|Purchase Date|\n",
      "+-------------+-----+-------------+\n",
      "|  plain donut|  1.5|   2018-04-17|\n",
      "|vanilla donut|  2.0|   2018-04-01|\n",
      "| glazed donut|  2.5|   2018-04-02|\n",
      "+-------------+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number, format_string, upper, lower, date_format, dayofmonth, month, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-------------+---------------+--------------------+--------------+--------------+--------------+---+-----+----+\n",
      "|   Donut Name|Price|Purchase Date|Price Formatted|      Name Formatted|Name Uppercase|Name Lowercase|Date Formatted|Day|Month|Year|\n",
      "+-------------+-----+-------------+---------------+--------------------+--------------+--------------+--------------+---+-----+----+\n",
      "|  plain donut|  1.5|   2018-04-17|           1.50| awesome plain donut|   PLAIN DONUT|   plain donut|      20180417| 17|    4|2018|\n",
      "|vanilla donut|  2.0|   2018-04-01|           2.00|awesome vanilla d...| VANILLA DONUT| vanilla donut|      20180401|  1|    4|2018|\n",
      "| glazed donut|  2.5|   2018-04-02|           2.50|awesome glazed donut|  GLAZED DONUT|  glazed donut|      20180402|  2|    4|2018|\n",
      "+-------------+-----+-------------+---------------+--------------------+--------------+--------------+--------------+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.withColumn(\"Price Formatted\", format_number(\"Price\", 2))\n",
    "  .withColumn(\"Name Formatted\", format_string(\"awesome %s\", \"Donut Name\"))\n",
    "  .withColumn(\"Name Uppercase\", upper(col(\"Donut Name\")))\n",
    "  .withColumn(\"Name Lowercase\", lower(col(\"Donut Name\")))\n",
    "  .withColumn(\"Date Formatted\", date_format(\"Purchase Date\", \"yyyyMMdd\"))\n",
    "  .withColumn(\"Day\", dayofmonth(\"Purchase Date\"))\n",
    "  .withColumn(\"Month\", month(\"Purchase Date\"))\n",
    "  .withColumn(\"Year\", year(\"Purchase Date\"))\n",
    "  .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
